import os
import argparse
import glob
from pathlib import Path
import cv2
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True'
os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
os.environ['CUDNN_BENCHMARK'] = 'True'

from ultralytics import YOLO
import torch
import pandas as pd
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
import time
from tqdm import tqdm
import numpy as np

def calculate_box_center(box):
    """ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì  ê³„ì‚°"""
    x1, y1, x2, y2 = box[:4]
    center_x = (x1 + x2) / 2
    center_y = (y1 + y2) / 2
    return center_x, center_y

def calculate_distance(center1, center2):
    """ë‘ ì¤‘ì‹¬ì  ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
    return np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)

def is_static_object(current_boxes, previous_detections, frame_idx, threshold_distance=30, min_consecutive_frames=3):
    """
    í˜„ì¬ í”„ë ˆì„ì˜ ë°•ìŠ¤ë“¤ì´ ì •ì  ê°ì²´ì¸ì§€ íŒë‹¨
    
    Args:
        current_boxes: í˜„ì¬ í”„ë ˆì„ì˜ ë°•ìŠ¤ë“¤ (í…ì„œ ë˜ëŠ” numpy ë°°ì—´)
        previous_detections: ì´ì „ í”„ë ˆì„ë“¤ì˜ íƒì§€ ê¸°ë¡ (frame_idxë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬)
        frame_idx: í˜„ì¬ í”„ë ˆì„ ì¸ë±ìŠ¤
        threshold_distance: ê°™ì€ ìœ„ì¹˜ë¡œ íŒë‹¨í•  ê±°ë¦¬ ì„ê³„ê°’ (í”½ì…€)
        min_consecutive_frames: í•„í„°ë§í•  ìµœì†Œ ì—°ì† í”„ë ˆì„ ìˆ˜
    
    Returns:
        filtered_boxes: í•„í„°ë§ëœ ë°•ìŠ¤ë“¤ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    # current_boxesê°€ í…ì„œì¸ ê²½ìš° numpyë¡œ ë³€í™˜
    if torch.is_tensor(current_boxes):
        current_boxes = current_boxes.cpu().numpy()
    
    if frame_idx < min_consecutive_frames - 1:
        # ì¶©ë¶„í•œ ì´ì „ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ëª¨ë“  ë°•ìŠ¤ ìœ ì§€
        return list(range(len(current_boxes)))
    
    filtered_boxes = []
    
    for box_idx, current_box in enumerate(current_boxes):
        # current_boxë„ numpy ë°°ì—´ë¡œ í™•ì‹¤íˆ ë³€í™˜
        if torch.is_tensor(current_box):
            current_box = current_box.cpu().numpy()
            
        current_center = calculate_box_center(current_box)
        is_static = True
        
        # ì´ì „ ì—°ì† í”„ë ˆì„ë“¤ì—ì„œ ë¹„ìŠ·í•œ ìœ„ì¹˜ì˜ ë°•ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        consecutive_count = 0
        
        for prev_frame_offset in range(1, min_consecutive_frames):
            prev_frame_idx = frame_idx - prev_frame_offset
            
            if prev_frame_idx not in previous_detections:
                is_static = False
                break
            
            # ì´ì „ í”„ë ˆì„ì—ì„œ ë¹„ìŠ·í•œ ìœ„ì¹˜ì˜ ë°•ìŠ¤ ì°¾ê¸°
            found_similar = False
            for prev_box in previous_detections[prev_frame_idx]:
                prev_center = calculate_box_center(prev_box)
                distance = calculate_distance(current_center, prev_center)
                
                if distance < threshold_distance:
                    found_similar = True
                    consecutive_count += 1
                    break
            
            if not found_similar:
                is_static = False
                break
        
        # ì—°ì†ëœ í”„ë ˆì„ì—ì„œ ëª¨ë‘ ë¹„ìŠ·í•œ ìœ„ì¹˜ì— ìˆìœ¼ë©´ ì •ì  ê°ì²´ë¡œ íŒë‹¨
        if not is_static or consecutive_count < min_consecutive_frames - 1:
            filtered_boxes.append(box_idx)
    
    return filtered_boxes

def parse_args():
    # ì²« ë²ˆì§¸ ì¸ìë¥¼ í™•ì¸í•˜ì—¬ ëª¨ë“œ ê²°ì •
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == 'combine':
        # combine ëª¨ë“œ
        parser = argparse.ArgumentParser(description='íƒì§€ ê²°ê³¼ CSV íŒŒì¼ë“¤ í†µí•©')
        parser.add_argument('mode', choices=['combine'], help='ì‹¤í–‰ ëª¨ë“œ')
        parser.add_argument('--run_dir', '-r', type=str, required=True,
                            help='ê²°ê³¼ê°€ ì €ì¥ëœ runs/detect í•˜ìœ„ í´ë” ê²½ë¡œ')
        return parser.parse_args()
    else:
        # ê¸°ë³¸ detect ëª¨ë“œ
        parser = argparse.ArgumentParser(description='YOLOë¥¼ ì‚¬ìš©í•œ ë™ì˜ìƒ ê°ì²´ íƒì§€')
        parser.add_argument('--input_dir', '-i', type=str, required=True,
                            help='ì…ë ¥ ë™ì˜ìƒ íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œ')
        parser.add_argument('--run_name', '-n', type=str, default=None,
                            help='ì‹¤í–‰ ì´ë¦„ (ê¸°ë³¸ê°’: detect_YYYYMMDD_HHMMSS í˜•ì‹ìœ¼ë¡œ ìë™ ìƒì„±)')
        parser.add_argument('--model', '-m', type=str, default='./pt_model/FLY_37LB4.pt',
                            help='YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ./pt_model/FLY_37LB4.pt)')
        parser.add_argument('--conf', type=float, default=0.25,
                            help='ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.25)')
        parser.add_argument('--iou', type=float, default=0.7,
                            help='NMS IoU ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.7)')
        parser.add_argument('--device', type=str, default='0',
                            help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (0: GPU, cpu: CPU)')
        parser.add_argument('--vid_stride', type=int, default=10,
                            help='ë¹„ë””ì˜¤ í”„ë ˆì„ ìŠ¤íŠ¸ë¼ì´ë“œ (ê¸°ë³¸ê°’: 10)')
        parser.add_argument('--start', '-s', type=int, default=None,
                            help='ì²˜ë¦¬í•  ë™ì˜ìƒì˜ ì‹œì‘ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)')
        parser.add_argument('--end', '-e', type=int, default=None,
                            help='ì²˜ë¦¬í•  ë™ì˜ìƒì˜ ë ì¸ë±ìŠ¤ (í¬í•¨)')
        parser.add_argument('--worker', '-w', type=int, default=2,
                            help='ë™ì‹œì— ì²˜ë¦¬í•  ìŠ¤ë ˆë“œ ìˆ˜ (ê¸°ë³¸ê°’: 2)')
        parser.add_argument('--reverse', '-r', action='store_true',
                            help='ë™ì˜ìƒ íŒŒì¼ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì²˜ë¦¬')
        parser.add_argument('--filter_static', action='store_true',
                            help='ì—°ì†ëœ í”„ë ˆì„ì—ì„œ ê°™ì€ ìœ„ì¹˜ì˜ ì •ì  ê°ì²´ í•„í„°ë§ (ê¸°ë³¸ê°’: False)')
        parser.add_argument('--static_threshold', type=float, default=30.0,
                            help='ì •ì  ê°ì²´ íŒë‹¨ì„ ìœ„í•œ ê±°ë¦¬ ì„ê³„ê°’ (í”½ì…€, ê¸°ë³¸ê°’: 30.0)')
        parser.add_argument('--static_frames', type=int, default=3,
                            help='ì •ì  ê°ì²´ë¡œ íŒë‹¨í•  ìµœì†Œ ì—°ì† í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸ê°’: 3)')
        return parser.parse_args()

def get_video_files(input_path):
    """ì…ë ¥ ê²½ë¡œì—ì„œ ë™ì˜ìƒ íŒŒì¼ë“¤ì„ ì°¾ì•„ ë°˜í™˜ (í•˜ìœ„ í´ë” í¬í•¨)"""
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
    video_files = []
    
    input_path = Path(input_path)
    
    if input_path.is_file():
        # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš°
        if input_path.suffix.lower() in video_extensions:
            video_files.append(str(input_path))
    elif input_path.is_dir():
        # í´ë”ì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  ë™ì˜ìƒ íŒŒì¼ ì°¾ê¸°
        for ext in video_extensions:
            # ** íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ ê²€ìƒ‰
            pattern = f'**/*{ext}'
            found_files = list(input_path.glob(pattern))
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
            found_files.extend(list(input_path.glob(pattern.upper())))
            
            # ì¤‘ë³µ ì œê±°í•˜ê³  ë¬¸ìì—´ë¡œ ë³€í™˜
            for file in found_files:
                file_str = str(file)
                if file_str not in video_files:
                    video_files.append(file_str)
    
    # íŒŒì¼ ê²½ë¡œë¡œ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ ìˆœì„œ ë³´ì¥
    video_files.sort()
    
    return video_files

# ì „ì—­ ë³€ìˆ˜ë¡œ lockê³¼ ì²˜ë¦¬ ì •ë³´ ê´€ë¦¬
print_lock = Lock()
process_counter = {'completed': 0, 'total': 0}
position_manager = {'current': 0, 'lock': Lock()}

def process_video(video_path, model_path, run_dir, args, input_base_dir, video_index):
    """YOLO í˜•ì‹ì— ë§ì¶° íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ê°œì„ ëœ ë²„ì „"""
    video_path = Path(video_path)
    video_name = video_path.stem
    
    # ë™ì˜ìƒì˜ ì´ í”„ë ˆì„ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    cap = cv2.VideoCapture(str(video_path))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    
    # ê° ìŠ¤ë ˆë“œì—ì„œ ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_path)
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    frames_dir = Path(run_dir) / 'detected_frames'
    frames_dir.mkdir(parents=True, exist_ok=True)
    
    original_frames_dir = Path(run_dir) / 'original_frames'
    original_frames_dir.mkdir(parents=True, exist_ok=True)
    
    csv_dir = Path(run_dir) / 'csv_results'
    csv_dir.mkdir(parents=True, exist_ok=True)
    
    # YOLO ì‹¤í–‰
    results = model.predict(
        source=video_path,
        save=False,
        save_txt=True,
        save_conf=True,
        project='runs/detect',
        name=Path(run_dir).name,
        exist_ok=True,
        conf=args.conf,
        iou=args.iou,
        max_det=300,
        device=args.device,
        stream=True,
        verbose=False,
        vid_stride=args.vid_stride,
        line_width=2,
        visualize=False,
        augment=False,
        agnostic_nms=False,
        retina_masks=False,
        classes=None,
    )
    
    # ê²°ê³¼ ì²˜ë¦¬
    all_detections = []
    saved_frames = set()
    previous_detections = {}
    filtered_count = 0
    
    # ì§„í–‰ë¥  í‘œì‹œ
    effective_frames = total_frames // args.vid_stride
    display_name = video_name[:30] + "..." if len(video_name) > 30 else video_name
    
    with position_manager['lock']:
        my_position = position_manager['current']
        position_manager['current'] += 1
    
    progress_bar = tqdm(
        total=effective_frames,
        desc=f"[{video_index:02d}] {display_name}",
        unit="í”„ë ˆì„",
        position=my_position,
        leave=True,
        ncols=120,
        bar_format='{desc:>40}: {percentage:3.0f}%|{bar:40}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',
        colour='green'
    )
    
    # ì—¬ê¸°ê°€ í•µì‹¬ ë¶€ë¶„ì…ë‹ˆë‹¤!
    # frame_idxëŠ” YOLOê°€ ì‚¬ìš©í•˜ëŠ” ì¸ë±ìŠ¤ì™€ ë™ì¼í•©ë‹ˆë‹¤
    for frame_idx, result in enumerate(results):
        progress_bar.update(1)
        boxes = result.boxes
        
        # ì‹¤ì œ í”„ë ˆì„ ë²ˆí˜¸ ê³„ì‚°
        actual_frame = frame_idx * args.vid_stride
        
        if boxes is not None and boxes.data.shape[0] > 0:
            # ì •ì  ê°ì²´ í•„í„°ë§ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
            if args.filter_static:
                valid_box_indices = is_static_object(
                    boxes.data, 
                    previous_detections, 
                    frame_idx,
                    threshold_distance=args.static_threshold,
                    min_consecutive_frames=args.static_frames
                )
                filtered_count += len(boxes.data) - len(valid_box_indices)
                
                if len(valid_box_indices) > 0:
                    valid_boxes = [boxes.data[i] for i in valid_box_indices]
                else:
                    valid_boxes = []
            else:
                valid_boxes = boxes.data
                valid_box_indices = list(range(boxes.data.shape[0]))
            
            # í˜„ì¬ í”„ë ˆì„ì˜ ë°•ìŠ¤ ì •ë³´ ì €ì¥
            current_frame_boxes = []
            for box in boxes.data:
                current_frame_boxes.append(box.cpu().numpy())
            previous_detections[frame_idx] = current_frame_boxes
            
            # ì˜¤ë˜ëœ í”„ë ˆì„ ì •ë³´ ì‚­ì œ
            if len(previous_detections) > 10:
                oldest_frame = min(previous_detections.keys())
                del previous_detections[oldest_frame]
            
            # í•„í„°ë§ëœ ë°•ìŠ¤ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì €ì¥
            if len(valid_boxes) > 0:
                if actual_frame not in saved_frames:
                    # ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤!
                    # YOLOì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥: video_name_frame_idx
                    original_frame = result.orig_img
                    
                    # YOLO í˜•ì‹: {video_name}_{frame_idx}.jpg
                    original_frame_filename = original_frames_dir / f'{video_name}_{frame_idx}.jpg'
                    cv2.imwrite(str(original_frame_filename), original_frame)
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„ë„ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ
                    annotated_frame = result.plot()
                    frame_filename = frames_dir / f'{video_name}_{frame_idx}.jpg'
                    cv2.imwrite(str(frame_filename), annotated_frame)
                    
                    saved_frames.add(actual_frame)
                
                # CSV ë°ì´í„° ìˆ˜ì§‘ (ê¸°ì¡´ê³¼ ë™ì¼)
                for box_idx in valid_box_indices:
                    box = boxes.data[box_idx]
                    x1, y1, x2, y2, conf, cls = box.cpu().numpy()
                    
                    detection = {
                        'video_name': video_name,
                        'frame': actual_frame,  # CSVì—ëŠ” ì‹¤ì œ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥
                        'frame_idx': frame_idx,  # YOLO ì¸ë±ìŠ¤ë„ í•¨ê»˜ ì €ì¥
                        'class_name': model.names[int(cls)],
                        'confidence': float(conf),
                        'x1': float(x1),
                        'y1': float(y1),
                        'x2': float(x2),
                        'y2': float(y2),
                        'width': float(x2 - x1),
                        'height': float(y2 - y1),
                        'center_x': float((x1 + x2) / 2),
                        'center_y': float((y1 + y2) / 2),
                    }
                    all_detections.append(detection)
    
    # DataFrame ìƒì„± ë° CSV ì €ì¥
    df = pd.DataFrame(all_detections)
    
    # ê²°ê³¼ ì¶œë ¥
    with print_lock:
        if args.filter_static:
            print(f"\n[{video_index:02d}] {video_name}: ì´ {len(all_detections)}ê°œ ê°ì²´ íƒì§€ë¨ (ì •ì  ê°ì²´ {filtered_count}ê°œ í•„í„°ë§ë¨)")
        else:
            print(f"\n[{video_index:02d}] {video_name}: ì´ {len(all_detections)}ê°œ ê°ì²´ íƒì§€ë¨")
    
    # CSV ì €ì¥
    csv_path = csv_dir / f'{video_name}_detections.csv'
    df.to_csv(csv_path, index=False)
    
    # íŒŒì¼ í¬ê¸° í™•ì¸
    if csv_path.exists():
        file_size = csv_path.stat().st_size
        with print_lock:
            print(f"    CSV ì €ì¥ ì™„ë£Œ: {csv_path.name} ({file_size} bytes)")
    
    # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì™„ë£Œ
    progress_bar.colour = 'blue'
    progress_bar.set_description(f"[{video_index:02d}] {display_name} âœ“")
    progress_bar.refresh()
    progress_bar.close()
    
    with print_lock:
        process_counter['completed'] += 1
    
    return df

def combine_all_results(run_dir, print_stats=True):
    """runs/detect/{run_name}/csv_results ì•ˆì˜ ëª¨ë“  CSV íŒŒì¼ì„ ì½ì–´ì„œ í†µí•©
    
    Args:
        run_dir: ê²°ê³¼ê°€ ì €ì¥ëœ runs/detect í•˜ìœ„ ë””ë ‰í† ë¦¬
        print_stats: í†µê³„ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
        
    Returns:
        combined_df: í†µí•©ëœ DataFrame (ì—†ìœ¼ë©´ None)
        csv_files: ì°¾ì€ CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    """
    run_dir = Path(run_dir)
    csv_dir = run_dir / 'csv_results'
    csv_files = list(csv_dir.glob('*_detections.csv'))
    
    if not csv_files:
        if print_stats:
            print(f"\nâš ï¸  {csv_dir}ì—ì„œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, []
    
    if print_stats:
        print(f"\nğŸ“‚ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ í†µí•©í•©ë‹ˆë‹¤...")
    
    all_dataframes = []
    for csv_file in csv_files:
        try:
            df = pd.read_csv(csv_file)
            all_dataframes.append(df)
        except Exception as e:
            if print_stats:
                print(f"âš ï¸  {csv_file} ì½ê¸° ì‹¤íŒ¨: {e}")
    
    if not all_dataframes:
        if print_stats:
            print(f"âš ï¸  í†µí•©í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, csv_files
    
    # DataFrame í†µí•©
    combined_df = pd.concat(all_dataframes, ignore_index=True)
    
    # ê²°ê³¼ ì €ì¥ - runs/detect/{run_name} ë””ë ‰í† ë¦¬ì— ì €ì¥
    combined_csv = run_dir / 'all_detections_combined.csv'
    combined_df.to_csv(combined_csv, index=False)
    
    if print_stats:
        print(f"âœ… í†µí•© ì™„ë£Œ: {combined_csv}")
        print(f"\nğŸ“Š í†µí•© ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì´ íƒì§€ ê°ì²´: {len(combined_df):,}ê°œ")
        print(f"   - í†µí•©ëœ ë™ì˜ìƒ: {combined_df['video_name'].nunique()}ê°œ")
        
        # í´ë˜ìŠ¤ë³„ íƒì§€ ìˆ˜
        if 'class_name' in combined_df.columns and len(combined_df) > 0:
            print(f"\nğŸ“‹ ì „ì²´ í´ë˜ìŠ¤ë³„ íƒì§€ ìˆ˜:")
            class_counts = combined_df['class_name'].value_counts()
            for class_name, count in class_counts.items():
                percentage = (count / len(combined_df)) * 100
                print(f"   - {class_name}: {count:,}ê°œ ({percentage:.1f}%)")
            
            # ìƒìœ„ 10ê°œ í´ë˜ìŠ¤ë§Œ ë³´ì—¬ì£¼ê¸° (í´ë˜ìŠ¤ê°€ ë§ì€ ê²½ìš°)
            if len(class_counts) > 10:
                print(f"\n   (ì´ {len(class_counts)}ê°œ í´ë˜ìŠ¤ ì¤‘ ìƒìœ„ 10ê°œë§Œ í‘œì‹œ)")
    
    return combined_df, csv_files


def main():
    args = parse_args()
    
    # PyTorch ìµœì í™”
    torch.backends.cudnn.benchmark = True
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True
    
    print(f"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
    torch.cuda.empty_cache()
    
    # run_name ìƒì„± (ì§€ì •í•˜ì§€ ì•Šì€ ê²½ìš° íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©)
    if args.run_name is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        run_name = f"detect_{timestamp}"
    else:
        run_name = args.run_name
    
    # runs/detect ì•„ë˜ì— ì‹¤í–‰ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
    run_dir = Path('runs/detect') / run_name
    run_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {run_dir}")
    
    # ì‹¤í–‰ ì •ë³´ë¥¼ ì €ì¥ (ë‚˜ì¤‘ì— ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡)
    run_info = {
        'run_name': run_name,
        'timestamp': datetime.now().isoformat(),
        'input_dir': args.input_dir,
        'model': args.model,
        'conf': args.conf,
        'iou': args.iou,
        'vid_stride': args.vid_stride,
        'filter_static': args.filter_static,
        'static_threshold': args.static_threshold if args.filter_static else None,
        'static_frames': args.static_frames if args.filter_static else None,
        'device': args.device,
        'worker': args.worker
    }
    
    # ì‹¤í–‰ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    with open(run_dir / 'run_info.json', 'w', encoding='utf-8') as f:
        json.dump(run_info, f, indent=2, ensure_ascii=False)
    
    # ì…ë ¥ ë™ì˜ìƒ íŒŒì¼ë“¤ ì°¾ê¸°
    video_files = get_video_files(args.input_dir)
    
    if not video_files:
        print(f"âŒ {args.input_dir}ì—ì„œ ë™ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ì´ {len(video_files)}ê°œì˜ ë™ì˜ìƒ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # reverse ì˜µì…˜ì´ ì„¤ì •ëœ ê²½ìš° íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë’¤ì§‘ê¸°
    if args.reverse:
        video_files.reverse()
        print(f"ğŸ“Œ ë™ì˜ìƒ íŒŒì¼ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í–ˆìŠµë‹ˆë‹¤.")
    
    # startì™€ end ì¸ìì— ë”°ë¼ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìŠ¬ë¼ì´ì‹±
    if args.start is not None or args.end is not None:
        start_idx = args.start if args.start is not None else 0
        end_idx = args.end + 1 if args.end is not None else len(video_files)
        
        # ì¸ë±ìŠ¤ ë²”ìœ„ ê²€ì¦
        if start_idx < 0:
            start_idx = 0
        if end_idx > len(video_files):
            end_idx = len(video_files)
        
        if start_idx >= end_idx:
            print(f"âŒ ì˜ëª»ëœ ë²”ìœ„: start({args.start})ê°€ end({args.end})ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìŠµë‹ˆë‹¤.")
            return
        
        # ì›ë³¸ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì™€ ìŠ¬ë¼ì´ì‹±ëœ ë¦¬ìŠ¤íŠ¸ ì •ë³´ ì¶œë ¥
        print(f"ğŸ“Œ ì„ íƒëœ ë²”ìœ„: ì¸ë±ìŠ¤ {start_idx}ë¶€í„° {end_idx-1}ê¹Œì§€")
        video_files = video_files[start_idx:end_idx]
        print(f"âœ… ì²˜ë¦¬í•  ë™ì˜ìƒ: {len(video_files)}ê°œ")
        
        # ì„ íƒëœ íŒŒì¼ ëª©ë¡ ì¶œë ¥
        sort_order = "(ë‚´ë¦¼ì°¨ìˆœ)" if args.reverse else "(ì˜¤ë¦„ì°¨ìˆœ)"
        print(f"\nì„ íƒëœ ë™ì˜ìƒ íŒŒì¼ {sort_order}:")
        base_path = Path(args.input_dir)
        for idx, file in enumerate(video_files, start=start_idx):
            # ìƒëŒ€ ê²½ë¡œ í‘œì‹œ
            try:
                relative_path = Path(file).relative_to(base_path)
                print(f"  [{idx}] {relative_path}")
            except ValueError:
                # ìƒëŒ€ ê²½ë¡œë¥¼ ë§Œë“¤ ìˆ˜ ì—†ëŠ” ê²½ìš° íŒŒì¼ëª…ë§Œ í‘œì‹œ
                print(f"  [{idx}] {Path(file).name}")
    
    # ì „ì—­ ì¹´ìš´í„° ì„¤ì •
    process_counter['total'] = len(video_files)
    process_counter['completed'] = 0
    position_manager['current'] = 0
    
    print(f"\nğŸš€ {args.worker}ê°œì˜ ìŠ¤ë ˆë“œë¡œ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print(f"ëª¨ë¸: {args.model}")
    
    # ì •ì  ê°ì²´ í•„í„°ë§ ì„¤ì • ì¶œë ¥
    if args.filter_static:
        print(f"ğŸ” ì •ì  ê°ì²´ í•„í„°ë§ í™œì„±í™”:")
        print(f"   - ê±°ë¦¬ ì„ê³„ê°’: {args.static_threshold} í”½ì…€")
        print(f"   - ìµœì†Œ ì—°ì† í”„ë ˆì„: {args.static_frames}ê°œ")
        print(f"   âš ï¸  ì—°ì† {args.static_frames}í”„ë ˆì„ ì´ìƒ ê°™ì€ ìœ„ì¹˜({args.static_threshold}px ì´ë‚´)ì— ë‚˜íƒ€ë‚˜ëŠ” ê°ì²´ëŠ” ì œê±°ë©ë‹ˆë‹¤.")
    else:
        print(f"ğŸ” ì •ì  ê°ì²´ í•„í„°ë§: ë¹„í™œì„±í™” (--filter_static ì˜µì…˜ìœ¼ë¡œ í™œì„±í™” ê°€ëŠ¥)")
    
    # GPU ì‚¬ìš© ì‹œ ë©€í‹°ìŠ¤ë ˆë“œ ê²½ê³ 
    if args.worker > 1 and args.device != 'cpu':
        print(f"âš ï¸  ì£¼ì˜: GPU ì‚¬ìš© ì‹œ {args.worker}ê°œì˜ ìŠ¤ë ˆë“œê°€ GPU ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•©ë‹ˆë‹¤.")
        print(f"   ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ --worker ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜ --device cpuë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    print(f"\nğŸ“Š ê° ë™ì˜ìƒì˜ ì²˜ë¦¬ ì§„í–‰ë¥ ì´ ì•„ë˜ì— í‘œì‹œë©ë‹ˆë‹¤:")
    print("="*100)
    
    start_time = time.time()
    
    # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
    try:
        with ThreadPoolExecutor(max_workers=args.worker) as executor:
            # ê° ë¹„ë””ì˜¤ íŒŒì¼ì— ëŒ€í•œ future ìƒì„±
            future_to_video = {
                executor.submit(process_video, video_file, args.model, run_dir, args, args.input_dir, idx+1): (video_file, idx)
                for idx, video_file in enumerate(video_files)
            }
            
            # ì™„ë£Œëœ ì‘ì—…ë“¤ ì²˜ë¦¬
            for future in as_completed(future_to_video):
                video_file, idx = future_to_video[future]
                try:
                    df = future.result()
                    # ê°œë³„ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ (CSVëŠ” ì´ë¯¸ ì €ì¥ë¨)
                except Exception as e:
                    with print_lock:
                        print(f"âŒ {video_file} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        import traceback
                        traceback.print_exc()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨. ì§„í–‰ì¤‘ì¸ ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤...")
        executor.shutdown(wait=False)
        return
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    # ëª¨ë“  í”„ë¡œê·¸ë ˆìŠ¤ ë°”ê°€ í‘œì‹œëœ í›„ì— í†µê³„ ì¶œë ¥
    print("\n" * (position_manager['current'] + 2))
    print("="*100)
    print(f"\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ì „ì²´ í†µê³„:")
    print(f"   - ì²˜ë¦¬ëœ ë™ì˜ìƒ: {len(video_files)}ê°œ")
    print(f"   - ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ (í‰ê· : {processing_time/len(video_files):.2f}ì´ˆ/ì˜ìƒ)")
    print(f"   - ì‚¬ìš©ëœ ìŠ¤ë ˆë“œ ìˆ˜: {args.worker}ê°œ")
    print(f"   - ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {run_dir}")
    
    # ìë™ìœ¼ë¡œ CSV íŒŒì¼ë“¤ í†µí•©
    print("\nğŸ“Š CSV íŒŒì¼ í†µí•©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    combined_df, csv_files = combine_all_results(run_dir)
    
    print(f"\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“ ê²°ê³¼ í™•ì¸:")
    print(f"   - íƒì§€ëœ í”„ë ˆì„ ì´ë¯¸ì§€: {run_dir}/detected_frames/")
    print(f"   - ê°œë³„ CSV íŒŒì¼ë“¤: {run_dir}/csv_results/")
    print(f"   - í†µí•© CSV íŒŒì¼: {run_dir}/all_detections_combined.csv")
    print(f"   - YOLO í…ìŠ¤íŠ¸ íŒŒì¼: {run_dir}/labels/")

if __name__ == '__main__': 
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'combine':
        # ê²°ê³¼ í†µí•©ë§Œ ì‹¤í–‰
        args = parse_args()
        # runs/detect ì•„ë˜ì˜ íŠ¹ì • í´ë”ì—ì„œ ê²°ê³¼ í†µí•©
        run_dir = Path('runs/detect') / args.run_dir
        if not run_dir.exists():
            print(f"âŒ {run_dir} ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            combined_df, csv_files = combine_all_results(run_dir)
    else:
        # ê¸°ë³¸ ë™ì‘: ê°ì²´ íƒì§€ ì‹¤í–‰
        main()
